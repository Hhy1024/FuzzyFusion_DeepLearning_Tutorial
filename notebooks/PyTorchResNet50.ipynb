{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Convolutional Neural Networks with PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Neural Models in PyTorch\n",
    "\n",
    "\n",
    "<span style=\"font-size:1.5em; color:blue\">In this session, we will learn to use deep models provide by PyTorch from the `torchvision` package to create a classifier and perform cross validation.</span>\n",
    "\n",
    "### ResNet50 \n",
    "\n",
    "Reference [ResNet - Deep Residual Learning for Image Recognition](https://arxiv.org/abs/1512.03385)\n",
    "\n",
    "![images/resnet50_kaggle.png MISSING](images/resnet50_kaggle.png)\n",
    "\n",
    "**_Image from [Kaggle.com](https://kaggle.com)_**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import psycopg2\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tranfer Learning with ResNet50\n",
    "\n",
    "## Instantiating a model with new classifier\n",
    "\n",
    "<span style=\"font-size:1.5em; color:blue\">First, we create a pretrained model from `torchvision.models`.\n",
    "Then we change the final fully connected layer with a `torch.nn.Linear` layer and specify the number of input/output features.</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify number of classes\n",
    "NUM_CLASS = 45\n",
    "\n",
    "def build_res50(fname_load=None):\n",
    "    model = models.resnet50(pretrained=(fname_load is None))\n",
    "    model.fc = torch.nn.Linear(in_features=2048, out_features=NUM_CLASS)\n",
    "    if fname_load:\n",
    "        print('Loading pretrained weights.')\n",
    "        model.load_state_dict(torch.load(fname_load))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepping Data Set for Training\n",
    "\n",
    "<span style=\"font-size:1.5em; color:blue\">In this stage we will prepare the dataset for cross validation.\n",
    "<br/>\n",
    "This is a little example that uses 3 classes with 200 images per class from RESISC45 dataset.\n",
    "<br/>\n",
    "We define a class which inherits from torch.utils.data.Dataset as an to load data for PyTorch models. \n",
    "<br/>\n",
    "The `ImageDataset` class takes (image, class_label) as input metadata and loads the image from the disk as well.\n",
    "<br/>\n",
    "We have staged these metadata in a PostgreSQL database to facilitate cross validation, among other possible analyses, but we will also provide this metadata in a CSV format in the repository, so you do not have to rely on PostgreSQL.\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = '/dsa/data/IEEE/RESISC45'\n",
    "METADATA = 'host=pgsql-ieee.dsa.lan dbname=resisc45 user=readonly_user password=fuzzieee'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset, metadata, transform):\n",
    "        self.dataset = Path(dataset)\n",
    "        self.transform = transform\n",
    "        self.metadata = metadata\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        frame_id, image, class_label = self.metadata[idx]\n",
    "        fname = str(self.dataset / image)\n",
    "        return dict(frame_id=frame_id, image=self.transform(Image.open(fname).convert(\"RGB\")), label=class_label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xval_metadata(fold, test=False):\n",
    "    print('Loading (traintest)', '=>', ('test' if test else 'train'))\n",
    "    with psycopg2.connect(METADATA) as conn:\n",
    "        with conn.cursor() as cur:\n",
    "            if test:\n",
    "                sql = \"\"\"\n",
    "                    select id, image, class_label from (select id, image, class_label, row_number()\n",
    "                    over (partition by class_label order by random())\n",
    "                    from frame where class_label in (3,8,33)) as foo\n",
    "                    where row_number %% 5 = %s and row_number<201;\n",
    "                \"\"\"\n",
    "            else:\n",
    "                sql = \"\"\"\n",
    "                    select id, image, class_label from (select id, image, class_label, row_number()\n",
    "                    over (partition by class_label order by random())\n",
    "                    from frame where class_label in (3,8,33)) as foo\n",
    "                    where row_number %% 5 != %s and row_number<201;\n",
    "                \"\"\"\n",
    "            cur.execute(sql, (fold,))\n",
    "            return cur.fetchall()\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:1.5em; color:blue\">After each image is loaded a preprocessing pipeline can be supplied to PyTorch as well.\n",
    "Here's an example, where we resize the input images and convert them into PyTorch tensors (from `PIL.Image`) and normalize.\n",
    "</span>\n",
    "\n",
    "> Some of the pipeline operations may only applied to tensors, others may be only applicable to images.\n",
    "> This is also the reason we arrage the pipeline operations in such an order. Please refer to PyTorch documentation to find out more about the pipeline usage.\n",
    "> ref: https://pytorch.org/docs/stable/torchvision/transforms.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_pipe = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize(\n",
    "        size=(299, 299)\n",
    "    ),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exporting metadata to .csv\n",
    "\n",
    "In case you do not wish to rely on PostgreSQL, you may use the csv exports as metadata to initialize the `ImageDataset`. This is also available at `datafiles/*.csv`."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "for fold in range(5):\n",
    "    print(\"Fold\", fold)\n",
    "    df = pd.DataFrame(xval_metadata(fold, test=False), columns=['id', 'image', 'class_label'])\n",
    "    df.drop(['id'], axis=1, inplace=True)\n",
    "    print('exported', len(df))\n",
    "    df.to_csv(f'xval-{fold}.train.csv')\n",
    "    df = pd.DataFrame(xval_metadata(fold, test=True), columns=['id', 'image', 'class_label'])\n",
    "    df.drop(['id'], axis=1, inplace=True)\n",
    "    df.to_csv(f'xval-{fold}.test.csv')\n",
    "    print('exported', len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:1.5em; color:blue\">\n",
    "To make use of this data, replace the xval_metadata() function and have it read from the CSVs.\n",
    " </span>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "\n",
    "#### NEW DEFINITION (switch Cell Type to code to run)\n",
    "def xval_metadata(fold, test=False):\n",
    "    return list(pd.read_csv(f'../datafiles/xval-{fold}.{\"test\" if test else \"train\"}.csv', index_col=0).itertuples())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters\n",
    "\n",
    "\n",
    "<span style=\"font-size:1.5em; color:blue\">Hyperparameters are the variables which determines the network and the training configuration,\n",
    "e.g. units of neurons in each layer or the learning rate or the batch size.  \n",
    "They are parameters that are not getting changed by the optimization algorithm,\n",
    "and typically they remain constants throughout the network training.\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify number of epochs per x-fold\n",
    "#EPOCHS = 15\n",
    "EPOCHS = 5\n",
    "\n",
    "# Specify batch size for training and testing\n",
    "BATCH_SIZE = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "<span style=\"font-size:1.5em; color:blue\">Below we are going to define the training loop for cross validation,\n",
    "for each cross fold, where will be a training data set with 20% held out for validation.\n",
    "The training and testing procedure within each cross validation iteration are the same as a standard train/test procedure, only with different data.</span>\n",
    "\n",
    "First we create a little utility function to help progress reporting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import IntProgress\n",
    "from IPython.display import display\n",
    "def progress_wrapper(iter_in, label='Fold Progress'):\n",
    "    m = len(iter_in)-1\n",
    "    pbar = IntProgress(description=label, min=0, max=m)\n",
    "    display(pbar)\n",
    "    for idx, item in enumerate(iter_in):\n",
    "        pbar.value = idx\n",
    "        yield item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, epochs, fname_save=None, xval_fold=None, lr=1e-3, is_inception=False):\n",
    "    train_data = ImageDataset(\n",
    "        dataset=DATASET,\n",
    "        metadata=xval_metadata(xval_fold, test=False),\n",
    "        transform=transform_pipe\n",
    "    )\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_data,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True\n",
    "    )\n",
    "    test_data = ImageDataset(\n",
    "        dataset=DATASET,\n",
    "        metadata=xval_metadata(xval_fold, test=True),\n",
    "        transform=transform_pipe\n",
    "    )\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        test_data,\n",
    "        batch_size=BATCH_SIZE\n",
    "    )\n",
    "\n",
    "    # optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    for i in range(epochs):\n",
    "        model.train()\n",
    "        ###################\n",
    "        #     TRAINING    #\n",
    "        ###################\n",
    "        samples = 0\n",
    "        loss_sum = 0\n",
    "        true_sum = 0\n",
    "        for batch in progress_wrapper(train_loader, 'train'):\n",
    "            X = batch[\"image\"]\n",
    "            labels = batch[\"label\"]\n",
    "            optimizer.zero_grad()\n",
    "            with torch.set_grad_enabled(True):\n",
    "                if is_inception:\n",
    "                    # ref: https://pytorch.org/tutorials/beginner/finetuning_torchvision_models_tutorial.html\n",
    "                    y, aux_outputs = model(X)\n",
    "                    loss1 = criterion(y, labels)\n",
    "                    loss2 = criterion(aux_outputs, labels)\n",
    "                    loss = loss1 + 0.4*loss2\n",
    "                else:\n",
    "                    y = model(X)\n",
    "                    loss = criterion(y, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                loss_sum += loss.item() * X.shape[0]\n",
    "                samples += X.shape[0]\n",
    "                num_true = torch.sum(torch.argmax(y, 1) == labels)\n",
    "                true_sum += num_true\n",
    "\n",
    "        epoch_acc = float(true_sum) / float(samples)\n",
    "        epoch_loss = float(loss_sum) / float(samples)\n",
    "        print(\"epoch: {} - {} loss: {}, acc: {}\".format(i + 1, \"train\", epoch_loss, epoch_acc))\n",
    "\n",
    "        ###################\n",
    "        #     TESTING     #\n",
    "        ###################\n",
    "        model.eval()\n",
    "        samples = 0\n",
    "        loss_sum = 0\n",
    "        true_sum = 0\n",
    "        for batch in test_loader:\n",
    "            X = batch[\"image\"]\n",
    "            labels = batch[\"label\"]\n",
    "            with torch.set_grad_enabled(False):\n",
    "                y = model(X)\n",
    "                loss = criterion(y, labels)\n",
    "                loss_sum += loss.item() * X.shape[0]\n",
    "                samples += X.shape[0]\n",
    "                num_true = torch.sum(torch.argmax(y, 1) == labels)\n",
    "                true_sum += num_true\n",
    "\n",
    "        epoch_acc = float(true_sum) / float(samples)\n",
    "        epoch_loss = float(loss_sum) / float(samples)\n",
    "        print(\"epoch: {} - {} loss: {}, acc: {}\".format(i + 1, \"test\", epoch_loss, epoch_acc))\n",
    "\n",
    "        ###################\n",
    "        #     SAVING      #\n",
    "        ###################\n",
    "        if fname_save:\n",
    "            torch.save(model.state_dict(), fname_save)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train - Test Methodolgies\n",
    "\n",
    "### Cross-Validation Example\n",
    "\n",
    "<span style=\"font-size:1.5em; color:blue\">You should see training progress such as this</span> (except the result are misleading because we have extremely downsampled to accelerate training in order to take a screenshot):\n",
    "\n",
    "![images/training.png](images/training.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fold in range(5):\n",
    "    print(\"Fold\", fold)\n",
    "    model = build_res50()\n",
    "    train(model, EPOCHS, xval_fold=fold, lr=1e-3, is_inception=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Congrats, Part 2 complete!\n",
    "\n",
    "**Appendix: extra source codes `src/`** \n",
    "\n",
    "* fusion_csv.sql - exporting cross validation metrics and inference data for the next data fusion stage\n",
    "* metadata-resisc45.py - creating metadata for the RESISC45 dataset\n",
    "* metadata-ucm.py - creating metadata for the UCMerced dataset\n",
    "* tables.sql - metadata schemas definition\n",
    "* train-resisc45.py - training ResNet50, Inception v3 and DenseNet on the RESISC45 dataset with cross validation\n",
    "* train-ucm.py - training ResNet50, Inception v3 and DenseNet on the UCMerced dataset with cross validation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
