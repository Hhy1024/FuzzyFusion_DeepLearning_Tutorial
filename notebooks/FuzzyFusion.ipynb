{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fuzzy Machine Learning Model Fusion\n",
    "\n",
    "<span style='font-size:1.5em; color:blue'>\n",
    " In this notebook, we will be working with the results of inference processing on remote sensing data from three deep convolutional neural networks (DCNN).\n",
    "</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Convolutional Neural Networks\n",
    "\n",
    "### ResNet50 \n",
    "\n",
    "![images/resnet50_kaggle.png MISSING](images/resnet50_kaggle.png)\n",
    "\n",
    "**_Image from [Kaggle.com](https://kaggle.com)_**\n",
    "\n",
    "\n",
    "\n",
    "### InceptionV3\n",
    "\n",
    "![images/inceptionv3_kaggle.png MISSING](images/inceptionv3_kaggle.png)\n",
    "\n",
    "**_Image from [Kaggle.com](https://kaggle.com)_**\n",
    "\n",
    "\n",
    "### DenseNet\n",
    "\n",
    "![images/densenet_towarddatascience.png MISSING](images/densenet_towarddatascience.png)\n",
    "\n",
    "**_Image from [TowardsDataScience.com](https://towardsdatascience.com/)_**\n",
    "\n",
    "### Further Reading / References\n",
    " * [ResNet - Deep Residual Learning for Image Recognition](https://arxiv.org/abs/1512.03385)\n",
    " * [InceptionV3 - Rethinking the Inception Architecture for Computer Vision](https://arxiv.org/abs/1512.00567)\n",
    " * [DenseNet - Densely Connected Convolutional Networks](https://arxiv.org/abs/1608.06993)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Data : Remote Sensing and Image Scene Classification\n",
    "\n",
    "<span style='font-size:1.5em; color:blue'>\n",
    " The [RESISC-45 data set is described here.](https://arxiv.org/abs/1703.00121)\n",
    " The data is composed of 45 classes of remote image scenes.\n",
    " Below is a sample of the RESISC-45 data from the _arxiv_ paper.\n",
    "</span>\n",
    "\n",
    "![images/RESISC45_p1.PNG MISSING](images/RESISC45_p1.PNG)\n",
    "![images/RESISC45_p2.PNG MISSING](images/RESISC45_p2.PNG)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## We did some heavy lifting for you!\n",
    "\n",
    "### aka - GPU Training\n",
    "![convfilters_giphy.gif MISSING](images/convfilters_giphy.gif)\n",
    "**_Image from [Giphy](https://media.giphy.com/media/metK0W9OSCoyQ/giphy.gif)_**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='font-size:1.5em; color:blue'>\n",
    " We have trained the three DCNN with the following hyperparameters:\n",
    "</span>\n",
    " * <span style='font-size:1.25em'>Epochs : 15</span>\n",
    " * <span style='font-size:1.25em'>Batch Size : 64</span>\n",
    " * <span style='font-size:1.25em'>Optimizer: Adam </span>\n",
    " * <span style='font-size:1.25em'>Initial Learning Rate: 1e-3</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='font-size:1.5em; color:blue'>\n",
    " Hardware\n",
    "</span>\n",
    " * <span style='font-size:1.25em'>Nvidia V100</span>\n",
    " * <span style='font-size:1.25em'>approximately 10 hours for each architecture's 5-fold experiments</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='font-size:1.5em; color:blue'>\n",
    "Performance Characteristics - 5-Fold Cross-Validation\n",
    "</span>\n",
    " * <span style='font-size:1.25em'>ResNet50 : 92.1%</span>\n",
    " * <span style='font-size:1.25em'>InceptionV3 : 60.6%</span>\n",
    " * <span style='font-size:1.25em'>DenseNet : 89.1%</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Fusion with the Choquet Fuzzy Integral\n",
    "\n",
    "<span style='font-size:1.5em; color:blue'>\n",
    "We will be using the techniques of enhanced decision information fusion from [this publication](https://doi.org/10.1109/LGRS.2018.2839092).\n",
    "</span>\n",
    "\n",
    "![images/DCNN_Fusion_Framework_Vert.png MISSING](images/DCNN_Fusion_Framework_Vert.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choquet Fuzzy Integral\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('../src'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "import ChI\n",
    "import numpy as np\n",
    "import csv\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import pandas as pd\n",
    "import cvxopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def soft_max(samples):\n",
    "    # Normalizes each sample w.r.t. each sample (soft max)\n",
    "    for i in range(0, samples.shape[0]):  # for each sample\n",
    "        for j in range(0, samples.shape[1]):  # for each network\n",
    "            samples[i,j,:] = np.exp(samples[i, j, :]) / sum(np.exp(samples[i, j, :]))\n",
    "\n",
    "    return [samples]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify path for network outputs & csv containing cv accuracies\n",
    "network_path = '../datafiles/pred'\n",
    "cross_val_path = '../datafiles/cross_val'\n",
    "\n",
    "# set up variables\n",
    "image_names = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_files = [f for f in listdir(network_path) if isfile(join(network_path, f))] # this is for the data files\n",
    "cross_val = [f for f in listdir(cross_val_path) if isfile(join(cross_val_path, f))] # this is for the cv accuracies\n",
    "num_nets = csv_files.__len__() # how many nets? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9216391  0.6062524  0.89075804]\n"
     ]
    }
   ],
   "source": [
    "# Create dictionary to store samples\n",
    "data = dict.fromkeys(csv_files)\n",
    "\n",
    "# Read in all of the csv data into a dictionary\n",
    "densities = []\n",
    "for file in cross_val:\n",
    "    csv_data = []\n",
    "    data_info = np.genfromtxt((cross_val_path + '/' + file), usecols=(1), skip_header=True,dtype=\"f\", delimiter=',')\n",
    "    densities.append(np.mean(data_info))\n",
    "\n",
    "densities = np.asarray(densities)\n",
    "print(densities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pred.densenet.5fold::A.csv', 'pred.inception.5fold::A.csv', 'pred.res50.5fold::A.csv']\n"
     ]
    }
   ],
   "source": [
    "first_net = 1 # this is a flag.\n",
    "print(csv_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in csv_files:\n",
    "    csv_data = []\n",
    "    data_info = np.genfromtxt((network_path + '/' + file), usecols=(1, 2, 3), dtype=\"|U\", delimiter=',') \n",
    "    confidence_vectors = np.genfromtxt((network_path + '/' + file), delimiter=';')\n",
    "\n",
    "    for line in range(0, data_info.__len__()):\n",
    "        if first_net:\n",
    "            image_names.append(data_info[line,0])\n",
    "        csv_data.append(np.hstack((data_info[line,:-1], data_info[line,2].partition(';')[0], confidence_vectors[line, 1:])))\n",
    "\n",
    "    first_net = 0\n",
    "    data[file] = csv_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# How many classes are there?\n",
    "num_classes = confidence_vectors.shape[1]# Assuming the first 4 columns are 'image\ty_true\tconfidence\ty_pred'\n",
    "\n",
    "    # Now I need to build the samples and their corresponding labels\n",
    "    # There will be the same number of ChI's as there are classes(L0\n",
    "    # One ChI per class, so each one sample will turn into L samples\n",
    "num_samples = data_info.__len__()\n",
    "samples = np.zeros([num_samples, csv_files.__len__(), num_classes])\n",
    "label = np.zeros([num_samples, num_classes])\n",
    "\n",
    "samples_list = []\n",
    "\n",
    "for i in range(0,3):\n",
    "    samples_list.append(list(pd.read_csv(f'samples{0}.csv', header=None, index_col=0).itertuples()))\n",
    "samples = np.asarray(samples_list).transpose(1,0,2)\n",
    "label = np.asarray(list(pd.read_csv(f'label.csv', header=None, index_col=0).itertuples()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Starting Training and Testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:5: RuntimeWarning: overflow encountered in exp\n",
      "  \"\"\"\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:5: RuntimeWarning: invalid value encountered in true_divide\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Training--\n",
      "Class ChI 0\n",
      "[0.92163908 0.60625237 0.97117915 0.89075804 0.9944276  0.95895167\n",
      " 1.        ]\n",
      "Class ChI 1\n",
      "[0.92163908 0.60625237 0.97117915 0.89075804 0.9944276  0.95895167\n",
      " 1.        ]\n",
      "Class ChI 2\n",
      "[0.92163908 0.60625237 0.97117915 0.89075804 0.9944276  0.95895167\n",
      " 1.        ]\n",
      "Class ChI 3\n",
      "[0.92163908 0.60625237 0.97117915 0.89075804 0.9944276  0.95895167\n",
      " 1.        ]\n",
      "Class ChI 4\n",
      "[0.92163908 0.60625237 0.97117915 0.89075804 0.9944276  0.95895167\n",
      " 1.        ]\n",
      "Class ChI 5\n",
      "[0.92163908 0.60625237 0.97117915 0.89075804 0.9944276  0.95895167\n",
      " 1.        ]\n",
      "Class ChI 6\n",
      "[0.92163908 0.60625237 0.97117915 0.89075804 0.9944276  0.95895167\n",
      " 1.        ]\n",
      "Class ChI 7\n",
      "[0.92163908 0.60625237 0.97117915 0.89075804 0.9944276  0.95895167\n",
      " 1.        ]\n",
      "Class ChI 8\n",
      "[0.92163908 0.60625237 0.97117915 0.89075804 0.9944276  0.95895167\n",
      " 1.        ]\n",
      "Class ChI 9\n",
      "[0.92163908 0.60625237 0.97117915 0.89075804 0.9944276  0.95895167\n",
      " 1.        ]\n",
      "Class ChI 10\n",
      "[0.92163908 0.60625237 0.97117915 0.89075804 0.9944276  0.95895167\n",
      " 1.        ]\n",
      "Class ChI 11\n",
      "[0.92163908 0.60625237 0.97117915 0.89075804 0.9944276  0.95895167\n",
      " 1.        ]\n",
      "Class ChI 12\n",
      "[0.92163908 0.60625237 0.97117915 0.89075804 0.9944276  0.95895167\n",
      " 1.        ]\n",
      "Class ChI 13\n",
      "[0.92163908 0.60625237 0.97117915 0.89075804 0.9944276  0.95895167\n",
      " 1.        ]\n",
      "Class ChI 14\n",
      "[0.92163908 0.60625237 0.97117915 0.89075804 0.9944276  0.95895167\n",
      " 1.        ]\n",
      "Class ChI 15\n",
      "[0.92163908 0.60625237 0.97117915 0.89075804 0.9944276  0.95895167\n",
      " 1.        ]\n",
      "Class ChI 16\n",
      "[0.92163908 0.60625237 0.97117915 0.89075804 0.9944276  0.95895167\n",
      " 1.        ]\n",
      "Class ChI 17\n",
      "[0.92163908 0.60625237 0.97117915 0.89075804 0.9944276  0.95895167\n",
      " 1.        ]\n",
      "Class ChI 18\n",
      "[0.92163908 0.60625237 0.97117915 0.89075804 0.9944276  0.95895167\n",
      " 1.        ]\n",
      "Class ChI 19\n",
      "[0.92163908 0.60625237 0.97117915 0.89075804 0.9944276  0.95895167\n",
      " 1.        ]\n",
      "Class ChI 20\n",
      "[0.92163908 0.60625237 0.97117915 0.89075804 0.9944276  0.95895167\n",
      " 1.        ]\n",
      "Class ChI 21\n",
      "[0.92163908 0.60625237 0.97117915 0.89075804 0.9944276  0.95895167\n",
      " 1.        ]\n",
      "Class ChI 22\n",
      "[0.92163908 0.60625237 0.97117915 0.89075804 0.9944276  0.95895167\n",
      " 1.        ]\n",
      "Class ChI 23\n",
      "[0.92163908 0.60625237 0.97117915 0.89075804 0.9944276  0.95895167\n",
      " 1.        ]\n",
      "Class ChI 24\n",
      "[0.92163908 0.60625237 0.97117915 0.89075804 0.9944276  0.95895167\n",
      " 1.        ]\n",
      "Class ChI 25\n",
      "[0.92163908 0.60625237 0.97117915 0.89075804 0.9944276  0.95895167\n",
      " 1.        ]\n",
      "Class ChI 26\n",
      "[0.92163908 0.60625237 0.97117915 0.89075804 0.9944276  0.95895167\n",
      " 1.        ]\n",
      "Class ChI 27\n",
      "[0.92163908 0.60625237 0.97117915 0.89075804 0.9944276  0.95895167\n",
      " 1.        ]\n",
      "Class ChI 28\n",
      "[0.92163908 0.60625237 0.97117915 0.89075804 0.9944276  0.95895167\n",
      " 1.        ]\n",
      "Class ChI 29\n",
      "[0.92163908 0.60625237 0.97117915 0.89075804 0.9944276  0.95895167\n",
      " 1.        ]\n",
      "Class ChI 30\n",
      "[0.92163908 0.60625237 0.97117915 0.89075804 0.9944276  0.95895167\n",
      " 1.        ]\n",
      "Class ChI 31\n",
      "[0.92163908 0.60625237 0.97117915 0.89075804 0.9944276  0.95895167\n",
      " 1.        ]\n",
      "Class ChI 32\n",
      "[0.92163908 0.60625237 0.97117915 0.89075804 0.9944276  0.95895167\n",
      " 1.        ]\n",
      "Class ChI 33\n",
      "[0.92163908 0.60625237 0.97117915 0.89075804 0.9944276  0.95895167\n",
      " 1.        ]\n",
      "Class ChI 34\n",
      "[0.92163908 0.60625237 0.97117915 0.89075804 0.9944276  0.95895167\n",
      " 1.        ]\n",
      "Class ChI 35\n",
      "[0.92163908 0.60625237 0.97117915 0.89075804 0.9944276  0.95895167\n",
      " 1.        ]\n",
      "Class ChI 36\n",
      "[0.92163908 0.60625237 0.97117915 0.89075804 0.9944276  0.95895167\n",
      " 1.        ]\n",
      "Class ChI 37\n",
      "[0.92163908 0.60625237 0.97117915 0.89075804 0.9944276  0.95895167\n",
      " 1.        ]\n",
      "Class ChI 38\n",
      "[0.92163908 0.60625237 0.97117915 0.89075804 0.9944276  0.95895167\n",
      " 1.        ]\n",
      "Class ChI 39\n",
      "[0.92163908 0.60625237 0.97117915 0.89075804 0.9944276  0.95895167\n",
      " 1.        ]\n",
      "Class ChI 40\n",
      "[0.92163908 0.60625237 0.97117915 0.89075804 0.9944276  0.95895167\n",
      " 1.        ]\n",
      "Class ChI 41\n",
      "[0.92163908 0.60625237 0.97117915 0.89075804 0.9944276  0.95895167\n",
      " 1.        ]\n",
      "Class ChI 42\n",
      "[0.92163908 0.60625237 0.97117915 0.89075804 0.9944276  0.95895167\n",
      " 1.        ]\n",
      "Class ChI 43\n",
      "[0.92163908 0.60625237 0.97117915 0.89075804 0.9944276  0.95895167\n",
      " 1.        ]\n",
      "Class ChI 44\n",
      "[0.92163908 0.60625237 0.97117915 0.89075804 0.9944276  0.95895167\n",
      " 1.        ]\n"
     ]
    }
   ],
   "source": [
    "##############################################\n",
    "# Start Training and Testing\n",
    "##############################################\n",
    "print('--Starting Training and Testing')\n",
    "\n",
    "train_samples = samples.copy()\n",
    "train_labels  = label\n",
    "\n",
    "test_samples = samples.copy()\n",
    "test_labels = label\n",
    "##############################################\n",
    "# Normalize Training Data & Testing Data\n",
    "##############################################\n",
    "[train_samples] = soft_max(train_samples)\n",
    "[test_samples] = soft_max(test_samples)\n",
    "\n",
    "print('--Training--')\n",
    "##############################################\n",
    "# Train the ChI(s)\n",
    "##############################################\n",
    "\n",
    "CHIs = []\n",
    "for j in range(0, num_classes):\n",
    "    CHIs.append(ChI.ChoquetIntegral())\n",
    "\n",
    "for j, chi in enumerate(CHIs):\n",
    "    print('Class ChI {}'.format(j))\n",
    "    tr = chi.train_chi_sugeno(densities)\n",
    "    print(chi.fm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Testing--\n",
      "0.9993761696818465\n"
     ]
    }
   ],
   "source": [
    "print('--Testing--')\n",
    "##############################################\n",
    "# Test the ChI(s)\n",
    "##############################################\n",
    "exper_out, known_out = [], []\n",
    "dec = []\n",
    "for j in range(0, test_samples.shape[0]): # for each data point\n",
    "    out = []\n",
    "    for k, chi in enumerate(CHIs): # for each ChI\n",
    "        test_sample = np.transpose(test_samples[j, :, k])\n",
    "        test_label = np.argmax(test_labels[j, :])\n",
    "        out.append(chi.chi_sugeno(test_sample))\n",
    "    out = np.asarray(out)\n",
    "    exper_out.append(np.argmax(out))\n",
    "    known_out.append(test_label)\n",
    "for i in range(0, exper_out.__len__()):\n",
    "    if exper_out[i] == known_out[i]:\n",
    "        dec.append(1)\n",
    "    else:\n",
    "        dec.append(0)\n",
    "with open('Results{}.csv'.format(i), 'w', newline='') as csvfile:\n",
    "    spamwriter = csv.writer(csvfile, delimiter=',')\n",
    "    for k in range(0, exper_out.__len__()):\n",
    "        spamwriter.writerow([exper_out[k], known_out[k]])\n",
    "\n",
    "acc = np.sum(dec) / dec.__len__()\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Training--\n",
      "[[[8.10686725e-03 9.91584782e-01 1.68251057e-04 ... 5.73747486e-08\n",
      "   1.11606210e-06 6.75650366e-12]\n",
      "  [8.10686725e-03 9.91584782e-01 1.68251057e-04 ... 5.73747486e-08\n",
      "   1.11606210e-06 6.75650366e-12]\n",
      "  [8.10686725e-03 9.91584782e-01 1.68251057e-04 ... 5.73747486e-08\n",
      "   1.11606210e-06 6.75650366e-12]]\n",
      "\n",
      " [[2.11738797e-02 1.08142790e-08 3.49496266e-08 ... 3.84348733e-10\n",
      "   2.63677546e-08 6.17516461e-10]\n",
      "  [2.11738797e-02 1.08142790e-08 3.49496266e-08 ... 3.84348733e-10\n",
      "   2.63677546e-08 6.17516461e-10]\n",
      "  [2.11738797e-02 1.08142790e-08 3.49496266e-08 ... 3.84348733e-10\n",
      "   2.63677546e-08 6.17516461e-10]]\n",
      "\n",
      " [[5.55360225e-02 1.04346388e-08 3.37227038e-08 ... 3.70855994e-10\n",
      "   2.54421024e-08 5.95838261e-10]\n",
      "  [5.55360225e-02 1.04346388e-08 3.37227038e-08 ... 3.70855994e-10\n",
      "   2.54421024e-08 5.95838261e-10]\n",
      "  [5.55360225e-02 1.04346388e-08 3.37227038e-08 ... 3.70855994e-10\n",
      "   2.54421024e-08 5.95838261e-10]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[           nan 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00]\n",
      "  [           nan 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00]\n",
      "  [           nan 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00]]\n",
      "\n",
      " [[           nan 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00]\n",
      "  [           nan 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00]\n",
      "  [           nan 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00]]\n",
      "\n",
      " [[           nan 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00]\n",
      "  [           nan 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00]\n",
      "  [           nan 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00]]]\n",
      "Class ChI 0\n",
      "Number Inputs :  3 ; Number Samples :  6412\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:      nan      nan  nan    nan    nan\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "domain error",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-054cdd52a005>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mtrain_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_samples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mlabel_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mtr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_chi_quad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fuzzieee_tutorial_2019/src/ChI.py\u001b[0m in \u001b[0;36mtrain_chi_quad\u001b[0;34m(self, x1, l1)\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainSamples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Number Inputs : \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"; Number Samples : \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproduce_lattice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mchi_quad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fuzzieee_tutorial_2019/src/ChI.py\u001b[0m in \u001b[0;36mproduce_lattice\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_constraint_matrices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfm_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         sol = solvers.qp(matrix(2 * E, tc='d'), matrix(L.T, tc='d'), matrix(G, tc='d'), matrix(h, tc='d'),\n\u001b[0;32m---> 84\u001b[0;31m                          matrix(A, tc='d'), matrix(b, tc='d'))\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msol\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/cvxopt/coneprog.py\u001b[0m in \u001b[0;36mqp\u001b[0;34m(P, q, G, h, A, b, solver, kktsolver, initvals, **kwargs)\u001b[0m\n\u001b[1;32m   4483\u001b[0m             'residual as dual infeasibility certificate': dinfres}\n\u001b[1;32m   4484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4485\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mconeqp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkktsolver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkktsolver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/cvxopt/coneprog.py\u001b[0m in \u001b[0;36mconeqp\u001b[0;34m(P, q, G, h, dims, A, b, initvals, kktsolver, xnewcopy, xdot, xaxpy, xscal, ynewcopy, ydot, yaxpy, yscal, **kwargs)\u001b[0m\n\u001b[1;32m   2241\u001b[0m         \u001b[0;31m# lmbdasq = lambda o lambda.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2243\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0miters\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0mW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmisc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_scaling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlmbda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2244\u001b[0m         \u001b[0mmisc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mssqr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlmbdasq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlmbda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/cvxopt/misc.py\u001b[0m in \u001b[0;36mcompute_scaling\u001b[0;34m(s, z, lmbda, dims, mnl)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m     \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdims\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'l'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m     \u001b[0mW\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'd'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiv\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmnl\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mmnl\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmnl\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mmnl\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m     \u001b[0mW\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'di'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'd'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m     \u001b[0mlmbda\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmnl\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mmnl\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmnl\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mmnl\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmnl\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mmnl\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: domain error"
     ]
    }
   ],
   "source": [
    "# DATA DRIVEN\n",
    "print('--Training--')\n",
    "##############################################\n",
    "# Train the ChI(s)\n",
    "##############################################\n",
    "\n",
    "CHIs = []\n",
    "for j in range(0, num_classes):\n",
    "    CHIs.append(ChI.ChoquetIntegral())\n",
    "\n",
    "print(train_samples)\n",
    "      \n",
    "for j, chi in enumerate(CHIs):\n",
    "    print('Class ChI {}'.format(j))\n",
    "    train_data = np.transpose(train_samples[:,:,j])\n",
    "    label_data = train_labels[:, j]\n",
    "    tr = chi.train_chi_quad(train_data, label_data)\n",
    "    print(chi.fm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('--Testing--')\n",
    "##############################################\n",
    "# Test the ChI(s)\n",
    "##############################################\n",
    "exper_out, known_out = [], []\n",
    "dec = []\n",
    "for j in range(0, test_samples.shape[0]): # for each data point\n",
    "    out = []\n",
    "    for k, chi in enumerate(CHIs): # for each ChI\n",
    "        test_sample = np.transpose(test_samples[j, :, k])\n",
    "        test_label = np.argmax(test_labels[j, :])\n",
    "        out.append(chi.chi_quad(test_sample))\n",
    "    out = np.asarray(out)\n",
    "    exper_out.append(np.argmax(out))\n",
    "    known_out.append(test_label)\n",
    "for i in range(0, exper_out.__len__()):\n",
    "    if exper_out[i] == known_out[i]:\n",
    "        dec.append(1)\n",
    "    else:\n",
    "        dec.append(0)\n",
    "with open('Results{}.csv'.format(i), 'w', newline='') as csvfile:\n",
    "    spamwriter = csv.writer(csvfile, delimiter=',')\n",
    "    for k in range(0, exper_out.__len__()):\n",
    "        spamwriter.writerow([exper_out[k], known_out[k]])\n",
    "\n",
    "acc = np.sum(dec) / dec.__len__()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
